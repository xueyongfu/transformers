
[bert]
data_dir = Data/train_data
model_type = bert
model_name_or_path = os.path.expanduser("~") + "/models/chinese/bert/pytorch/bert-base-chinese"
task_name = sst-2
log_name = 分类
output_dir = output/checkpoint-131700
max_seq_length = 250
do_train = False
do_eval = True
eval_all_checkpoints = False
evaluate_during_training = True
do_lower_case = True
per_gpu_train_batch_size = 8
per_gpu_eval_batch_size = 8
gradient_accumulation_steps = 1
learning_rate = 5e-5
num_train_epochs = 30
warmup_steps = 100
overwrite_output_dir = True
overwrite_cache = False
logging_steps = 300
save_steps = 300

